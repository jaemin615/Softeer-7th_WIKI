## m2 팀미션

만약 이 데이터가 사람이 운행하는 차량의 데이터가 아니라 '자율주행차' 데이터라면 어떤 Data Product를 만들면 좋을까?

뉴욕 택시 데이터인 해당 데이터 살펴보고 뉴욕에서 자율주행 택시 플랫폼을 운영하는 기업에게 필요한 Data Product에 대해 생각해봄

생각해본 아이디어들
#### 수요 예측 기반 자율주행처 재배치 분석
자율주행차는 승객이 없어도 스스로 이동할 수 있음. 승객이 내린 후(`DOLocationID`) 다음 승객이 가장 많이 발생할 지역(`PULocationID`)을 시간대별(`datetime`)로 예측하여 차량을 미리 보내놓는 시스템 구축
    
- 승객의 대기 시간을 줄이고, 차량이 빈 차로 배회하는 거리를 최소화하여 운영 효율을 극대화

#### 정비 및 충전 스케줄링
 `trip_distance`를 누적 계산하여 자율주행차량의 노후도를 예측하고, 수요가 가장 적은 시간대와 장소(`DOLocationID`)를 파악해 자동으로 정비 스케줄을 잡는다.

#### 물류 운송 활용
시간 별로 승차량을 분석하여 승차 수요가 적은 시간대에는 퀵 같은 배송 서비스를 위해 차량 배차 

## m3 팀미션

주어진 링크의 포스트 읽고 난 후기

우선 10억 페이지를 25.5시간, $462에 크롤링 가능하다는 결과 자체가 신기했다. 저런 대규모 크롤러를 위해 어떻게 아키텍쳐를 구성해야 될지 생각해 본적이 없었는데 아키텍쳐를 구성하는 과정과 그렇게 하게 된 근거, 노드의 각 구성에 대한 설명 과정이 흥미로웠다.

결과 측면에서는 JS 렌더링 없이도 아직 크롤 가능한 웹이 생각보다 많다는 점이 인상 깊었다. 대부분의 웹이 리액트나 뷰 같은 프레임워크를 사용해서 클라이언드 사이드 렌더링 방식을 쓴다고 생각했는데 HTML만 파싱하여 <a> 태그를 활용하여 크롤링을 진행하는 방식으로도 많은 웹 페이지 정보가 수집될 수 있다는 결과가 예상 외였다. 한 편으로는 저자가 이야기한 것 처럼 JS 까지 다 포함해서 크롤링을 진행할려면 얼마나의 리소스가 들지 궁금해지기도 했다.
    
성능 상의 분석에서는 주요 병목 중 하나가 SSL 핸드쉐이크 과정이였다는 것이 신기했다. 흔히 생각할 수 있는 대역폭 문제가 아닌 SSL 핸드셰이크가 CPU의 25%를 먹는 수준으로 무서운 작업이라는 것이 인상 깊었다.


## AWS 수업

Role
- Role 부여하면 기존 user나 group으로 부여된 권한 덮어쓰기 됨
- Role의 경우 사용자나 ec2 / 람다 같은 컴퓨팅 리소스에 부여 가능

보안 설정 
- Security Group - instance 단위
  -  인바운드 포트 ssh, http, https만 열 것
- NACL - subnet 단위

맥북에서 Public EC2에 접근하기 위해 생성해야 하는 VPC 관련 리소스?
- 라우팅 테이블
- 보안 그룹
- 인터넷 게이트웨이
- Private EC2에 별도 DB 구축할 경우 NAT
	- NAT Gateway(managed service) 사용 말고 NAT 역할 하는 인스턴스 띄워서 할 것
	- Public IP 사용할경우 비용 관리 잘할 것

 EC2 - T 시리즈 최신 세대 micro 사용 가능
	
 람다 - 메모리 적게 할당해도 적은 메모리 때문에 실행 시간이 길면 비용이 더 나올 수도 있다. 비용 관리 잘할 것
